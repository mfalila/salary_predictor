{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - DISCOVER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling Helper Functions\n",
    "* Added a scripts directory and called it helpers\n",
    "* In helpers added a module <i/>helpers.py</i> that holds all our helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the helpers directory to path\n",
    "import sys\n",
    "sys.path.insert(0,'./helpers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import read_in_dataset, merge_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32m'00. Define Problem.ipynb'\u001b[0m*                             \u001b[01;32mdata_trans_pipe.PNG\u001b[0m*\r\n",
      "\u001b[01;32m'01. Data Preperation.ipynb'\u001b[0m*                           \u001b[34;42mderived_data\u001b[0m/\r\n",
      "\u001b[01;32m'02. Data_Exploration.ipynb'\u001b[0m*                           \u001b[34;42mhelpers\u001b[0m/\r\n",
      "\u001b[01;32m'03. Data_Preprocessing.ipynb'\u001b[0m*                         \u001b[34;42mraw_data\u001b[0m/\r\n",
      "\u001b[01;32m'04. Data_modeling .ipynb'\u001b[0m*                             \u001b[34;42munzipped_data\u001b[0m/\r\n",
      "\u001b[01;32m'Data Science Interview Assignment-Sam_Mfalila.docx'\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************** Reading in the train_salaries dataset *********************\n",
      "\n",
      "it has 1000000 rows and 2 columns\n",
      "n************************* It has the following columns**************************\n",
      "\n",
      "Index(['jobId', 'salary'], dtype='object')\n",
      "n********************** The first five rows look like this **********************\n",
      "\n",
      "              jobId  salary\n",
      "0  JOB1362684407687     130\n",
      "1  JOB1362684407688     101\n",
      "2  JOB1362684407689     137\n",
      "3  JOB1362684407690     142\n",
      "4  JOB1362684407691     163\n"
     ]
    }
   ],
   "source": [
    "#Reading salaries data\n",
    "salaries = helpers.read_in_dataset(\"train_salaries\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************** Reading in the train_features dataset *********************\n",
      "\n",
      "it has 1000000 rows and 8 columns\n",
      "n************************* It has the following columns**************************\n",
      "\n",
      "Index(['jobId', 'companyId', 'jobType', 'degree', 'major', 'industry',\n",
      "       'yearsExperience', 'milesFromMetropolis'],\n",
      "      dtype='object')\n",
      "n********************** The first five rows look like this **********************\n",
      "\n",
      "              jobId companyId         jobType       degree      major  \\\n",
      "0  JOB1362684407687    COMP37             CFO      MASTERS       MATH   \n",
      "1  JOB1362684407688    COMP19             CEO  HIGH_SCHOOL       NONE   \n",
      "2  JOB1362684407689    COMP52  VICE_PRESIDENT     DOCTORAL    PHYSICS   \n",
      "3  JOB1362684407690    COMP38         MANAGER     DOCTORAL  CHEMISTRY   \n",
      "4  JOB1362684407691     COMP7  VICE_PRESIDENT    BACHELORS    PHYSICS   \n",
      "\n",
      "  industry  yearsExperience  milesFromMetropolis  \n",
      "0   HEALTH               10                   83  \n",
      "1      WEB                3                   73  \n",
      "2   HEALTH               10                   38  \n",
      "3     AUTO                8                   17  \n",
      "4  FINANCE                8                   16  \n"
     ]
    }
   ],
   "source": [
    "#Reading features data\n",
    "features = helpers.read_in_dataset(\"train_features\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           9041        2090        4084         114        2867        6573\r\n",
      "Swap:          2047           0        2047\r\n"
     ]
    }
   ],
   "source": [
    "!free -m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many salary records dont have matching features?\n",
    "len(set(salaries.jobId) - set(features.jobId))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many feature records dont have matching salaries?\n",
    "len(set(features.jobId) - set(salaries.jobId))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " All salaries have matching features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a Dataset for Analysis\n",
    "\n",
    "We'll use the merged_dataset() stored earlier in our helper.py module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspecting the function\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def merge_dataset(salaries, features):\n",
      "\n",
      "    \"\"\"\n",
      "    Merging the salaries and features datasets. Both need to have a common key jobId\n",
      "\n",
      "    Keyword arguments:\n",
      "    salaries -- the dataframe of salary data\n",
      "    features -- the dataframe of features\n",
      "\n",
      "    Returns:\n",
      "    A pandas dataframe\n",
      "    \"\"\"\n",
      "    train_data_merged = salaries.merge(features, how='right', on ='jobId')\n",
      "\n",
      "    return train_data_merged\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(merge_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging data and removing raw datasets\n",
    "train_data_merged = merge_dataset(salaries, features)\n",
    "del salaries\n",
    "del features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobId</th>\n",
       "      <th>salary</th>\n",
       "      <th>companyId</th>\n",
       "      <th>jobType</th>\n",
       "      <th>degree</th>\n",
       "      <th>major</th>\n",
       "      <th>industry</th>\n",
       "      <th>yearsExperience</th>\n",
       "      <th>milesFromMetropolis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JOB1362684407687</td>\n",
       "      <td>130</td>\n",
       "      <td>COMP37</td>\n",
       "      <td>CFO</td>\n",
       "      <td>MASTERS</td>\n",
       "      <td>MATH</td>\n",
       "      <td>HEALTH</td>\n",
       "      <td>10</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JOB1362684407688</td>\n",
       "      <td>101</td>\n",
       "      <td>COMP19</td>\n",
       "      <td>CEO</td>\n",
       "      <td>HIGH_SCHOOL</td>\n",
       "      <td>NONE</td>\n",
       "      <td>WEB</td>\n",
       "      <td>3</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JOB1362684407689</td>\n",
       "      <td>137</td>\n",
       "      <td>COMP52</td>\n",
       "      <td>VICE_PRESIDENT</td>\n",
       "      <td>DOCTORAL</td>\n",
       "      <td>PHYSICS</td>\n",
       "      <td>HEALTH</td>\n",
       "      <td>10</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JOB1362684407690</td>\n",
       "      <td>142</td>\n",
       "      <td>COMP38</td>\n",
       "      <td>MANAGER</td>\n",
       "      <td>DOCTORAL</td>\n",
       "      <td>CHEMISTRY</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JOB1362684407691</td>\n",
       "      <td>163</td>\n",
       "      <td>COMP7</td>\n",
       "      <td>VICE_PRESIDENT</td>\n",
       "      <td>BACHELORS</td>\n",
       "      <td>PHYSICS</td>\n",
       "      <td>FINANCE</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              jobId  salary companyId         jobType       degree      major  \\\n",
       "0  JOB1362684407687     130    COMP37             CFO      MASTERS       MATH   \n",
       "1  JOB1362684407688     101    COMP19             CEO  HIGH_SCHOOL       NONE   \n",
       "2  JOB1362684407689     137    COMP52  VICE_PRESIDENT     DOCTORAL    PHYSICS   \n",
       "3  JOB1362684407690     142    COMP38         MANAGER     DOCTORAL  CHEMISTRY   \n",
       "4  JOB1362684407691     163     COMP7  VICE_PRESIDENT    BACHELORS    PHYSICS   \n",
       "\n",
       "  industry  yearsExperience  milesFromMetropolis  \n",
       "0   HEALTH               10                   83  \n",
       "1      WEB                3                   73  \n",
       "2   HEALTH               10                   38  \n",
       "3     AUTO                8                   17  \n",
       "4  FINANCE                8                   16  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 9)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a directory \"derived_data\" to store our modelling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p derived_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing our modeling data to a csv for loading on our next notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_merged.to_csv('derived_data/train_data_merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
